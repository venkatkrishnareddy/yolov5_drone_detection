{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatkrishnareddy/yolov5_drone_detection/blob/colabMaskTwoCls/Roboflow_Yolov3_MaskDetect_Single_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFhMDyD-vXLs"
      },
      "source": [
        "NOTE: For the most up to date version of this notebook, please be sure to copy from this link:\n",
        " \n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ByRi9d6_Yzu0nrEKArmLMLuMaZjYfygO#scrollTo=WgHANbxqWJPa)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4JQh5NPM5-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgHANbxqWJPa"
      },
      "source": [
        "\n",
        "ðŸ’¡ Recommendation: [Open this blog post](https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/) to continue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBrnMP72M6f3",
        "outputId": "4fe4415f-dab3-49bb-a99c-cf79a96b6f14"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## !git clone https://git_token@github.com/username/repository.git\n",
        "!rm -rf /content/yolov5_drone_detection/"
      ],
      "metadata": {
        "id": "pIBOlRRBJdbQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/venkatkrishnareddy/yolov5_drone_detection "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GSfIg3_NTsZ",
        "outputId": "72801962-3d0e-4360-fb51-b09c0a16a623"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5_drone_detection'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (204/204), done.\u001b[K\n",
            "remote: Total 212 (delta 12), reused 190 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (212/212), 21.00 MiB | 12.39 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov5_drone_detection/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9FYWriGJxUL",
        "outputId": "3a09c732-f3df-4304-b588-e936ea59095a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5_drone_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQCymxItJYmP",
        "outputId": "631530d9-446e-4844-a69f-c7a46de273cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " best_1.pt  'drone_images dataset link'   retina_net\n",
            " best_2.pt   README.md                    \u001b[0m\u001b[01;34mroboflowyolo3\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY4nnFcHNrPP",
        "outputId": "cba7f1e2-d436-41e3-df63-74dc05fd2ad0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch colabMaskTwoCls\n",
            "Your branch is up to date with 'origin/colabMaskTwoCls'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mmodified:   roboflowyolo3/LICENSE\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .; git commit -m \"yolo3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic_sJDU5Nx62",
        "outputId": "221eff8b-7de0-425b-b914-4b8867adfee0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@9a5682454ce8.(none)')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv_o45UOOKdO",
        "outputId": "eb59719d-7205-4b2b-eb64-293da9cf17b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaWLgkGnMp0g",
        "outputId": "d18362cc-4594-4e03-9906-e38ead9c9f9a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OJt1nB7LS3u",
        "outputId": "2343c65e-9888-4400-f91f-35d5e2340bed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* \u001b[32mmain\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/main\n",
            "  \u001b[31mremotes/origin/colabMaskTwoCls\u001b[m\n",
            "  \u001b[31mremotes/origin/main\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout colabMaskTwoCls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfckE7ElMd1M",
        "outputId": "095a005c-ab5f-42f6-8835-852a85e41f0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'colabMaskTwoCls' set up to track remote branch 'colabMaskTwoCls' from 'origin'.\n",
            "Switched to a new branch 'colabMaskTwoCls'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure that these version \n",
        "!python -c 'import tensorflow; print(\"TF:\", tensorflow.__version__)' # TF: 2.12.0\n",
        "!python -c 'import keras; print(\"K\", keras.__version__)'  # K 2.12.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a376cb36-eae4-45e2-9f20-55bab198a3d1",
        "id": "lXFLAoHxBdiR"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-28 13:36:21.079115: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 13:36:22.076542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "TF: 2.12.0\n",
            "2023-04-28 13:36:24.381039: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-28 13:36:25.365446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "K 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AmSSTFFWud7"
      },
      "source": [
        "**This cell below is only one you need to change to have YOLOv3 train on your own Roboflow dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5_drone_detection/roboflowyolo3/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUUMO1VezVHv",
        "outputId": "bf4dcdc7-d4cf-486f-f126-8fb2ea4167ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5_drone_detection/roboflowyolo3\n",
            "coco_annotation.py                           train_bottleneck.py\n",
            "convert.py                                   train.py\n",
            "darknet53.cfg                                Tutorial.ipynb\n",
            "\u001b[0m\u001b[01;34mfont\u001b[0m/                                        voc_annotation.py\n",
            "kmeans.py                                    \u001b[01;34myolo3\u001b[0m/\n",
            "LICENSE                                      yolo.py\n",
            "\u001b[01;34mmaskData\u001b[0m/                                    yolov3.cfg\n",
            "\u001b[01;34mmodel_data\u001b[0m/                                  yolov3-tiny.cfg\n",
            "README.md                                    yolo_video.py\n",
            "Roboflow-Yolov3-MaskDetectSingleClass.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJzW08g2VlwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f454fd45-6145-4dc3-9692-6af7ba683edd"
      },
      "source": [
        "# download our DarkNet weights \n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-28 13:38:07--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: â€˜yolov3.weightsâ€™\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  17.8MB/s    in 16s     \n",
            "\n",
            "2023-04-28 13:38:24 (14.9 MB/s) - â€˜yolov3.weightsâ€™ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyPfLjFBbOAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c901cd5-ec6e-4a2c-f292-cb473fdb006b"
      },
      "source": [
        "\n",
        "%ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coco_annotation.py                           train_bottleneck.py\n",
            "convert.py                                   train.py\n",
            "darknet53.cfg                                Tutorial.ipynb\n",
            "\u001b[0m\u001b[01;34mfont\u001b[0m/                                        voc_annotation.py\n",
            "kmeans.py                                    \u001b[01;34myolo3\u001b[0m/\n",
            "LICENSE                                      yolo.py\n",
            "\u001b[01;34mlogs\u001b[0m/                                        yolov3.cfg\n",
            "\u001b[01;34mmaskData\u001b[0m/                                    yolov3-tiny.cfg\n",
            "\u001b[01;34mmodel_data\u001b[0m/                                  yolov3.weights\n",
            "README.md                                    yolo_video.py\n",
            "Roboflow-Yolov3-MaskDetectSingleClass.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mub8GJMBVluA"
      },
      "source": [
        "!python convert.py yolov3.cfg yolov3.weights model_data/yolo.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48yw4UaOYgQS"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/;  ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ6B4uMYIbV7",
        "outputId": "208a7f70-215b-4cb9-96cc-8819cc9efbec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  yolov5_drone_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmkgfPqhIk3x",
        "outputId": "e77c093a-bc64-4df3-8675-bd7026d14f08"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodel_data/yolo.h5\u001b[m\n",
            "\t\u001b[31myolov3.weights\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVZBZRyAHsWf",
        "outputId": "9e023a73-80bb-4e54-b321-f132ac6792ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mmodel_data/yolo.h5\u001b[m\n",
            "\t\u001b[31myolov3.weights\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFX-2_M8bMQ3"
      },
      "source": [
        "## Use our model for inference\n",
        "\n",
        "For predictions, we'll call a a Python script called `yolo_video.py` with required arguments for our use case: a path to our specific first stage trained weights (see our blog for why we're using only stage one), a path to our custom class names, and a flag to specify we're using images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlVyevd8b8gG"
      },
      "source": [
        "Additional arguments for `yolo_video.py` are as follows:\n",
        "\n",
        "```\n",
        "usage: yolo_video.py [-h] [--model MODEL] [--anchors ANCHORS]\n",
        "                     [--classes CLASSES] [--gpu_num GPU_NUM] [--image]\n",
        "                     [--input] [--output]\n",
        "\n",
        "positional arguments:\n",
        "  --input        Video input path\n",
        "  --output       Video output path\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help         show this help message and exit\n",
        "  --model MODEL      path to model weight file, default model_data/yolo.h5\n",
        "  --anchors ANCHORS  path to anchor definitions, default\n",
        "                     model_data/yolo_anchors.txt\n",
        "  --classes CLASSES  path to class definitions, default\n",
        "                     model_data/coco_classes.txt\n",
        "  --gpu_num GPU_NUM  Number of GPU to use, default 1\n",
        "  --image            Image detection mode, will ignore all positional arguments\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcJbmgNEO1bE"
      },
      "source": [
        "!python yolo_video.py --model=\"./logs/000/trained_weights_stage_1.h5\" --classes=\"_classes.txt\" --image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbACT_RJdGVg"
      },
      "source": [
        "For input image names into the above, consider trying the following:\n",
        "\n",
        "- `00a7a49c47d51fd16a4cbb17e2d2cf86.jpg` # white-king works! + knight\n",
        "- `015d0d7ff365f0b7492ff079c8c7d56c.jpg` # black-queen mixes up\n",
        "- `176b28b5c417f39a9e5d37545fca5b4c.jpg` # finds only five\n",
        "- `4673f994f60a2ea7afdddc1b752947c0.jpg` # white-rook (thinks king)\n",
        "- `5ca7f0cb1c500554e65ad031190f8e9f.jpg` # white-pawn (missed white-king)\n",
        "- `fbf15139f38a46e02b5f4061c0c9b08f.jpg` # black-king success!\n",
        "\n",
        "You can view these images in your Colab notebook by clicking on the image name in the expanded left-hand panel (Files â†’ keras-yolo3 â†’ IMG_NAME )."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88oJlBl4dumo"
      },
      "source": [
        "## Move currently trained model to GDrive\n",
        "\n",
        "Optionally, you may want to save the new weights that your model trained so that the next time you run this notebook, you can either skip training and use these weights for inference or begin training where you left off with this weights file.\n",
        "\n",
        "Following the below will link your Colab notebook to your Google Drive, and save the weights (named as the current time you saved them to enforce a unique file name) in your Drive folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4t94dBNdsxz"
      },
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLe0Y4Z8BOVF"
      },
      "source": [
        "# create a copy of the weights file with a datetime \n",
        "# and move that file to your own Drive\n",
        "%cp ./logs/000/trained_weights_stage_1.h5 ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5\n",
        "%mv ./logs/000/trained_weights_stage_1_$(date +%F-%H:%M).h5 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}